{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the terminal command `mlflow server --host 127.0.0.1 --port 8080 \n",
    "`\n",
    "<br><br> Experiment to add window_size as a param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-05 13:05:31.711\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlisa.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[1mPROJ_ROOT path is: /Users/tomwilson/code/LISA\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import polars as pl\n",
    "from mlflow.models import infer_signature\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "from lisa.config import INTERIM_DATA_DIR, PLOTS_DIR\n",
    "from lisa.features import sliding_window, standard_scaler, train_test_split\n",
    "from lisa.modeling import random_forest\n",
    "from lisa import evaluate\n",
    "\n",
    "import os\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127:8080\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      "Windows:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-05 12:00:18.438\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlisa.features\u001b[0m:\u001b[36msliding_window\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mAggregating data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/site-packages/_distutils_hack/__init__.py:31: UserWarning: Setuptools is replacing distutils. Support for replacing an already imported distutils is deprecated. In the future, this condition will fail. Register concerns at https://github.com/pypa/setuptools/issues/new?template=distutils-deprecation.yml\n",
      "  warnings.warn(\n",
      "                                              \n",
      "Windows:   0%|          | 0/2 [09:31<?, ?it/s]        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-05 12:09:50.364\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlisa.features\u001b[0m:\u001b[36msliding_window\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mAggregating data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "Windows:  50%|█████     | 1/2 [21:55<21:55, 1315.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-05 12:22:13.997\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlisa.features\u001b[0m:\u001b[36msliding_window\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mAggregating data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "Windows:  50%|█████     | 1/2 [30:44<21:55, 1315.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-05 12:31:02.512\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlisa.features\u001b[0m:\u001b[36msliding_window\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mAggregating data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(54838) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Windows: 100%|██████████| 2/2 [41:56<00:00, 1258.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# ensure that mlruns are saved in the correct directory\n",
    "os.chdir(\"..\")\n",
    "\n",
    "input_path: Path = INTERIM_DATA_DIR / \"labelled_test_data.csv\"\n",
    "\n",
    "original_df = pl.read_csv(input_path)\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"RF Test\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run() as parent_run:\n",
    "    windows = [50, 150]\n",
    "    splits = [0.6, 0.7]\n",
    "    for window in tqdm(windows, desc=\"Windows\", position=0):\n",
    "        for split in tqdm(splits, desc=\"Splits\", leave=False, position=1):\n",
    "            with mlflow.start_run(nested=True, run_name=f\"W_{window}:S_{split}\"):\n",
    "\n",
    "                df = sliding_window(original_df, period=window, log=True)\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    df, train_size=split, gap=window\n",
    "                )\n",
    "\n",
    "                scaled_X_train, scaled_X_test, scaler = standard_scaler(X_train, X_test)\n",
    "\n",
    "                params = {\"n_estimators\": 100, \"max_depth\": 128}\n",
    "\n",
    "                model = random_forest.random_forest_classifier(\n",
    "                    scaled_X_train, y_train.to_numpy().ravel(), **params\n",
    "                )\n",
    "\n",
    "                accuracy = metrics.accuracy_score(y_test, model.predict(scaled_X_test))\n",
    "                labels = df[\"ACTIVITY\"].unique(maintain_order=True)\n",
    "                plot_path = PLOTS_DIR / \"tmp/confusion_matrix.png\"\n",
    "                cm = evaluate.confusion_matrix(model, labels, scaled_X_test, y_test, plot_path)\n",
    "                \n",
    "                # Log the hyperparameters\n",
    "                params[\"window\"] = window\n",
    "                params[\"split\"] = split\n",
    "                mlflow.log_params(params)\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_artifact(plot_path)\n",
    "\n",
    "                # Set a tag that we can use to remind ourselves what this run was for\n",
    "                mlflow.set_tag(\"Training Info\", \"Basic RF model for labelled test data\")\n",
    "\n",
    "                # Infer the model signature\n",
    "                signature = infer_signature(\n",
    "                    scaled_X_train, model.predict(scaled_X_train)\n",
    "                )\n",
    "\n",
    "                # Log the model\n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    artifact_path=\"rf_model\",\n",
    "                    signature=signature,\n",
    "                    input_example=scaled_X_train,\n",
    "                )\n",
    "\n",
    "                # Explicitly delete objects to free memory\n",
    "                del df, X_train, X_test, y_train, y_test, scaled_X_train, scaled_X_test, model, cm\n",
    "                gc.collect()  # Run garbage collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                              \n",
      "Windows:   0%|          | 0/1 [00:00<?, ?it/s]--- Logging error in Loguru Handler #1 ---\n",
      "Record was: {'elapsed': datetime.timedelta(seconds=3578, microseconds=539581), 'exception': None, 'extra': {}, 'file': (name='features.py', path='/Users/tomwilson/code/LISA/lisa/features.py'), 'function': 'sliding_window', 'level': (name='INFO', no=20, icon='ℹ️'), 'line': 134, 'message': 'Aggregating data...', 'module': 'features', 'name': 'lisa.features', 'process': (id=53608, name='MainProcess'), 'thread': (id=8256245568, name='MainThread'), 'time': datetime(2024, 9, 5, 12, 59, 51, 535830, tzinfo=datetime.timezone(datetime.timedelta(seconds=3600), 'BST'))}\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/site-packages/loguru/_handler.py\", line 206, in emit\n",
      "    self._sink.write(str_record)\n",
      "  File \"/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/site-packages/loguru/_simple_sinks.py\", line 122, in write\n",
      "    self._function(message)\n",
      "  File \"/Users/tomwilson/code/LISA/lisa/config.py\", line 37, in <lambda>\n",
      "    logger.add(lambda msg: tqdm.write(msg, end=\"\"), colorize=True)\n",
      "  File \"/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/site-packages/tqdm/std.py\", line 720, in write\n",
      "    with cls.external_write_mode(file=file, nolock=nolock):\n",
      "  File \"/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/site-packages/tqdm/std.py\", line 750, in external_write_mode\n",
      "    inst.refresh(nolock=True)\n",
      "  File \"/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/site-packages/tqdm/std.py\", line 1347, in refresh\n",
      "    self.display()\n",
      "  File \"/Users/tomwilson/micromamba/envs/LISA/lib/python3.10/site-packages/tqdm/notebook.py\", line 156, in display\n",
      "    ltext, pbar, rtext = self.container.children\n",
      "AttributeError: 'tqdm_notebook' object has no attribute 'container'\n",
      "--- End of logging error ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-05 12:59:51.535\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlisa.features\u001b[0m:\u001b[36msliding_window\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mAggregating data...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python(55583) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55585) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55590) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55591) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55592) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55594) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55595) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55596) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55597) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55598) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "python(55599) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# ensure that mlruns are saved in the correct directory\n",
    "from loguru import logger\n",
    "from scipy.stats import randint\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "input_path: Path = INTERIM_DATA_DIR / \"labelled_test_data.csv\"\n",
    "\n",
    "original_df = pl.read_csv(input_path)\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"RF Test\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run() as parent_run:\n",
    "    windows = [300]\n",
    "    splits = [0.8]\n",
    "    for window in tqdm(windows, desc=\"Windows\", position=0):\n",
    "        for split in tqdm(splits, desc=\"Splits\", leave=False, position=1):\n",
    "            with mlflow.start_run(nested=True, run_name=f\"W_{window}:S_{split}\"):\n",
    "\n",
    "                #  Feature engineering with params\n",
    "                df = sliding_window(original_df, period=window, log=True)\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    df, train_size=split, gap=window\n",
    "                )\n",
    "\n",
    "                scaled_X_train, scaled_X_test, scaler = standard_scaler(X_train, X_test)\n",
    "\n",
    "                # Tune model\n",
    "                param_dist = {\"n_estimators\": randint(50, 500), \"max_depth\": randint(10, 150)}\n",
    "\n",
    "                rf = RandomForestClassifier()\n",
    "                # Use random search to find the best hyperparameters\n",
    "                rand_search = RandomizedSearchCV(rf, param_distributions=param_dist, n_iter=5, cv=5, n_jobs=-1, random_state=42)\n",
    "                rand_search.fit(X_train, y_train)\n",
    "\n",
    "                model = rand_search.best_estimator_\n",
    "\n",
    "                # Print the best hyperparameters\n",
    "                logger.info(\"Best hyperparameters:\", rand_search.best_params_)\n",
    "                params = rand_search.best_params_\n",
    "\n",
    "                accuracy = metrics.accuracy_score(y_test, model.predict(scaled_X_test))\n",
    "                labels = df[\"ACTIVITY\"].unique(maintain_order=True)\n",
    "                plot_path = PLOTS_DIR / \"tmp/confusion_matrix.png\"\n",
    "                cm = evaluate.confusion_matrix(model, labels, scaled_X_test, y_test, plot_path)\n",
    "                \n",
    "                # Log the hyperparameters\n",
    "                params[\"window\"] = window\n",
    "                params[\"split\"] = split\n",
    "                mlflow.log_params(params)\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_artifact(plot_path)\n",
    "\n",
    "                # Set a tag that we can use to remind ourselves what this run was for\n",
    "                mlflow.set_tag(\"Training Info\", \"Basic RF model for labelled test data\")\n",
    "\n",
    "                # Infer the model signature\n",
    "                signature = infer_signature(\n",
    "                    scaled_X_train, model.predict(scaled_X_train)\n",
    "                )\n",
    "\n",
    "                # Log the model\n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    artifact_path=\"rf_model\",\n",
    "                    signature=signature,\n",
    "                    input_example=scaled_X_train,\n",
    "                )\n",
    "\n",
    "                # Explicitly delete objects to free memory\n",
    "                del df, X_train, X_test, y_train, y_test, scaled_X_train, scaled_X_test, model, cm\n",
    "                gc.collect()  # Run garbage collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to do the same with logistic regression!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Windows:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Windows:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-09-05 13:38:30.179\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mlisa.features\u001b[0m:\u001b[36msliding_window\u001b[0m:\u001b[36m134\u001b[0m - \u001b[1mAggregating data...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from lisa.modeling.logistic_regression import logistic_regression\n",
    "\n",
    "os.chdir(\"..\")\n",
    "\n",
    "input_path: Path = INTERIM_DATA_DIR / \"labelled_test_data.csv\"\n",
    "\n",
    "original_df = pl.read_csv(input_path)\n",
    "\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:8080\")\n",
    "\n",
    "# Create a new MLflow Experiment\n",
    "mlflow.set_experiment(\"LR Test\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run() as parent_run:\n",
    "    windows = [300]\n",
    "    splits = [0.8]\n",
    "    for window in tqdm(windows, desc=\"Windows\"):\n",
    "        for split in tqdm(splits, desc=\"Splits\"):\n",
    "            with mlflow.start_run(nested=True, run_name=f\"W_{window}:S_{split}\"):\n",
    "\n",
    "                df = sliding_window(original_df, period=window, log=True)\n",
    "\n",
    "                X_train, X_test, y_train, y_test = train_test_split(\n",
    "                    df, train_size=split, gap=window\n",
    "                )\n",
    "\n",
    "                scaled_X_train, scaled_X_test, scaler = standard_scaler(X_train, X_test)\n",
    "\n",
    "                model = logistic_regression(scaled_X_train, y_train)\n",
    "\n",
    "                accuracy = metrics.accuracy_score(y_test, model.predict(scaled_X_test))\n",
    "                labels = df[\"ACTIVITY\"].unique(maintain_order=True)\n",
    "                plot_path = PLOTS_DIR / \"tmp/confusion_matrix.png\"\n",
    "                cm = evaluate.confusion_matrix(model, labels, scaled_X_test, y_test, plot_path)\n",
    "                \n",
    "                # Log the hyperparameters\n",
    "                params = {}\n",
    "                params[\"window\"] = window\n",
    "                params[\"split\"] = split\n",
    "                mlflow.log_params(params)\n",
    "\n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"accuracy\", accuracy)\n",
    "                mlflow.log_artifact(plot_path)\n",
    "\n",
    "                # Set a tag that we can use to remind ourselves what this run was for\n",
    "                mlflow.set_tag(\"Training Info\", \"Basic LR model for labelled test data\")\n",
    "\n",
    "                # Infer the model signature\n",
    "                signature = infer_signature(\n",
    "                    scaled_X_train, model.predict(scaled_X_train)\n",
    "                )\n",
    "\n",
    "                # Log the model\n",
    "                mlflow.sklearn.log_model(\n",
    "                    sk_model=model,\n",
    "                    artifact_path=\"lr_model\",\n",
    "                    signature=signature,\n",
    "                    input_example=scaled_X_train,\n",
    "                )\n",
    "\n",
    "                # Explicitly delete objects to free memory\n",
    "                del df, X_train, X_test, y_train, y_test, scaled_X_train, scaled_X_test, model, cm\n",
    "                gc.collect()  # Run garbage collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
